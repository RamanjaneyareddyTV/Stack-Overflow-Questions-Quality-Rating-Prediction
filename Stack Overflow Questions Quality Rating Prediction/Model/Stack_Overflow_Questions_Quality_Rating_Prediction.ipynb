{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Overflow Questions Quality Rating Prediction\n",
    "\n",
    "![](https://miro.medium.com/max/1200/1*ROagAxRi9uL-jeFLy5wQEQ.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "1. Abstract\n",
    "2. Dataset\n",
    "3. Goal\n",
    "4. Importing all the required libraries and Dataset\n",
    "5. Data Cleaning\n",
    "6. Data Visualization or, EDA\n",
    "7. Prediction Models\n",
    "    - Logistic Regression\n",
    "    - Random forest Classifier\n",
    "    - Decision Tree Classifier\n",
    "    - KNN Classifier\n",
    "    - Naive Bayes Classifier\n",
    "    - XgBoosting Classifier\n",
    "8. Model Comparison\n",
    "9. Conclusion\n",
    "***********************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "Community Question Answering websites (CQA) have a growing popularity as a way of providing and searching of information. CQA attract users as they provide a direct and rapid way to find the desired information. As recognizing good questions can improve the CQA services and the userâ€™s experience, the current study focuses on question quality instead. Specifically, we predict question quality and investigate the features which influence it. The influence of the question tags, length of the question title and body, presence of a code snippet, the user reputation and terms used to formulate the question are tested. For each set of dependent variables, Ridge regression models are estimated. The results indicate that the inclusion of terms in the models improves their predictive power. Additionally, we investigate which lexical terms determine high and low quality questions. The terms with the highest and lowest coefficients are semantically analyzed. The analysis shows that terms predicting high quality are terms expressing, among others, excitement, negative experience or terms regarding exceptions. Terms predicting low quality questions are terms containing spelling errors or indicating off-topic questions and interjections.\n",
    "\n",
    "### Goal\n",
    "The gaol of this project is to make a prediction model which will predict the quality of the questions from the Stack Overflow website depending on the various factors.\n",
    "*****************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, plot_confusion_matrix, plot_precision_recall_curve\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data and don't use the low quality edit data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Some EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": false,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34552656</td>\n",
       "      <td>Java: Repeat Task Every Random Seconds</td>\n",
       "      <td>&lt;p&gt;I'm already familiar with repeating tasks e...</td>\n",
       "      <td>&lt;java&gt;&lt;repeat&gt;</td>\n",
       "      <td>2016-01-01 00:21:59</td>\n",
       "      <td>LQ_CLOSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34553034</td>\n",
       "      <td>Why are Java Optionals immutable?</td>\n",
       "      <td>&lt;p&gt;I'd like to understand why Java 8 Optionals...</td>\n",
       "      <td>&lt;java&gt;&lt;optional&gt;</td>\n",
       "      <td>2016-01-01 02:03:20</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34553174</td>\n",
       "      <td>Text Overlay Image with Darkened Opacity React...</td>\n",
       "      <td>&lt;p&gt;I am attempting to overlay a title over an ...</td>\n",
       "      <td>&lt;javascript&gt;&lt;image&gt;&lt;overlay&gt;&lt;react-native&gt;&lt;opa...</td>\n",
       "      <td>2016-01-01 02:48:24</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34553318</td>\n",
       "      <td>Why ternary operator in swift is so picky?</td>\n",
       "      <td>&lt;p&gt;The question is very simple, but I just cou...</td>\n",
       "      <td>&lt;swift&gt;&lt;operators&gt;&lt;whitespace&gt;&lt;ternary-operato...</td>\n",
       "      <td>2016-01-01 03:30:17</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34553755</td>\n",
       "      <td>hide/show fab with scale animation</td>\n",
       "      <td>&lt;p&gt;I'm using custom floatingactionmenu. I need...</td>\n",
       "      <td>&lt;android&gt;&lt;material-design&gt;&lt;floating-action-but...</td>\n",
       "      <td>2016-01-01 05:21:48</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                              Title  \\\n",
       "0  34552656             Java: Repeat Task Every Random Seconds   \n",
       "1  34553034                  Why are Java Optionals immutable?   \n",
       "2  34553174  Text Overlay Image with Darkened Opacity React...   \n",
       "3  34553318         Why ternary operator in swift is so picky?   \n",
       "4  34553755                 hide/show fab with scale animation   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I'm already familiar with repeating tasks e...   \n",
       "1  <p>I'd like to understand why Java 8 Optionals...   \n",
       "2  <p>I am attempting to overlay a title over an ...   \n",
       "3  <p>The question is very simple, but I just cou...   \n",
       "4  <p>I'm using custom floatingactionmenu. I need...   \n",
       "\n",
       "                                                Tags         CreationDate  \\\n",
       "0                                     <java><repeat>  2016-01-01 00:21:59   \n",
       "1                                   <java><optional>  2016-01-01 02:03:20   \n",
       "2  <javascript><image><overlay><react-native><opa...  2016-01-01 02:48:24   \n",
       "3  <swift><operators><whitespace><ternary-operato...  2016-01-01 03:30:17   \n",
       "4  <android><material-design><floating-action-but...  2016-01-01 05:21:48   \n",
       "\n",
       "          Y  \n",
       "0  LQ_CLOSE  \n",
       "1        HQ  \n",
       "2        HQ  \n",
       "3        HQ  \n",
       "4        HQ  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"D:/ML/Stack Overflow Questions Quality Rating Prediction/Dataset/train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the open questions are grouped under a single class (1), while the closed one is grouped under (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Java: Repeat Task Every Random Seconds</td>\n",
       "      <td>&lt;p&gt;I'm already familiar with repeating tasks e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why are Java Optionals immutable?</td>\n",
       "      <td>&lt;p&gt;I'd like to understand why Java 8 Optionals...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Text Overlay Image with Darkened Opacity React...</td>\n",
       "      <td>&lt;p&gt;I am attempting to overlay a title over an ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why ternary operator in swift is so picky?</td>\n",
       "      <td>&lt;p&gt;The question is very simple, but I just cou...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hide/show fab with scale animation</td>\n",
       "      <td>&lt;p&gt;I'm using custom floatingactionmenu. I need...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0             Java: Repeat Task Every Random Seconds   \n",
       "1                  Why are Java Optionals immutable?   \n",
       "2  Text Overlay Image with Darkened Opacity React...   \n",
       "3         Why ternary operator in swift is so picky?   \n",
       "4                 hide/show fab with scale animation   \n",
       "\n",
       "                                                Body  Y  \n",
       "0  <p>I'm already familiar with repeating tasks e...  0  \n",
       "1  <p>I'd like to understand why Java 8 Optionals...  2  \n",
       "2  <p>I am attempting to overlay a title over an ...  2  \n",
       "3  <p>The question is very simple, but I just cou...  2  \n",
       "4  <p>I'm using custom floatingactionmenu. I need...  2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['Id', 'Tags', 'CreationDate'], axis=1)\n",
    "data['Y'] = data['Y'].map({'LQ_CLOSE':0, 'LQ_EDIT': 1, 'HQ':2})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's join the title and the body of the text data so that we can use both of them in our classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Java: Repeat Task Every Random Seconds &lt;p&gt;I'm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Why are Java Optionals immutable? &lt;p&gt;I'd like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Text Overlay Image with Darkened Opacity React...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Why ternary operator in swift is so picky? &lt;p&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>hide/show fab with scale animation &lt;p&gt;I'm usin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y                                               text\n",
       "0  0  Java: Repeat Task Every Random Seconds <p>I'm ...\n",
       "1  2  Why are Java Optionals immutable? <p>I'd like ...\n",
       "2  2  Text Overlay Image with Darkened Opacity React...\n",
       "3  2  Why ternary operator in swift is so picky? <p>...\n",
       "4  2  hide/show fab with scale animation <p>I'm usin..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data['Title'] + ' ' + data['Body']\n",
    "data = data.drop(['Title', 'Body'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^(a-zA-Z)\\s]','', text)\n",
    "    return text\n",
    "data['text'] = data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data\n",
    "Let's now split the dataset into training and validation sets.\n",
    "\n",
    "**Training and Testing Dataset Spliting using the `train_test_split`**\n",
    "  \n",
    "  * Immporting the library from the sklearn.model_selection\n",
    "  * Split the dataset into 80:20 ratio\n",
    "  * x_train and y_train are the trainning datasets\n",
    "  * x_test and y_test are the testing datasets\n",
    "  * After the spliting of the datasets the model is ready to be prepared!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (9000,)\n",
      "Validation Data Shape: (9000,)\n"
     ]
    }
   ],
   "source": [
    "# Define how much percent data you wanna split\n",
    "split_pcent = 0.20\n",
    "split = int(split_pcent * len(data))\n",
    "\n",
    "# Shuffles dataframe\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Training Sets\n",
    "train = data[split:]\n",
    "trainX = train['text']\n",
    "trainY = train['Y'].values\n",
    "\n",
    "# Validation Sets\n",
    "valid = data[:split]\n",
    "validX = valid['text']\n",
    "validY = valid['Y'].values\n",
    "\n",
    "assert trainX.shape == trainY.shape\n",
    "assert validX.shape == validY.shape\n",
    "\n",
    "print(f\"Training Data Shape: {validX.shape}\\nValidation Data Shape: {validX.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing the Data\n",
    "Let's vectorize the data so it's in the numerical format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Load the vectorizer, fit on training set, transform on validation set\n",
    "vectorizer = TfidfVectorizer()\n",
    "trainX = vectorizer.fit_transform(trainX)\n",
    "validX = vectorizer.transform(validX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************\n",
    "##   Prediction Model Creation\n",
    "A classification model tries to draw some conclusion from the input values given for training. It will predict the class labels/categories for the new data.\n",
    "\n",
    "Here we are going to prepare several Classification machine learning models based on those we will do a comparative analysis that which model is better among them.\n",
    "\n",
    "We are using six different classification algorithms -\n",
    "* **K-Nearest Neighbours Algorithm** : K-Nearest Neighbour is one of the simplest Machine Learning algorithms based on Supervised Learning technique. K-NN algorithm assumes the similarity between the new case/data and available cases and put the new case into the category that is most similar to the available categories. K-NN algorithm stores all the available data and classifies a new data point based on the similarity. This means when new data appears then it can be easily classified into a well suite category by using K- NN algorithm.\n",
    "\n",
    "\n",
    "* **Random Forest Classifier** : Random Forest is a popular machine learning algorithm that belongs to the supervised learning technique. It can be used for both Classification and Regression problems in ML. It is based on the concept of ensemble learning, which is a process of combining multiple classifiers to solve a complex problem and to improve the performance of the model.\n",
    "\n",
    "\n",
    "* **Logistic Regression** : Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression).\n",
    "\n",
    "\n",
    "* **Naive Bayes Classifcation Algorithm** :  Naive Bayes classifiers are a family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong independence assumptions between the features. They are among the simplest Bayesian network models, but coupled with kernel density estimation, they can achieve higher accuracy levels.\n",
    "\n",
    "\n",
    "* **Decision Tree Classifier** : Decision Tree is a Supervised learning technique that can be used for both classification and Regression problems, but mostly it is preferred for solving Classification problems. It is a tree-structured classifier, where internal nodes represent the features of a dataset, branches represent the decision rules and each leaf node represents the outcome.\n",
    "\n",
    "\n",
    "* **XgBoost Classifier** : XGBoost is a decision-tree-based ensemble Machine Learning algorithm that uses a gradient boosting framework. In prediction problems involving unstructured data (images, text, etc.) A wide range of applications: Can be used to solve regression, classification, ranking, and user-defined prediction problems.\n",
    "\n",
    "Let's quickly get into the algorithms!\n",
    "*******************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression\n",
    "Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression).\n",
    "\n",
    "Let's first start with our good old, Logistic Regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and fit the classifier on the data\n",
    "lr_classifier = LogisticRegression(C=1.)\n",
    "lr_classifier.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy of Logsitic Regression Classifier is: 87.02%\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy score of the classifier\n",
    "print(f\"Validation Accuracy of Logsitic Regression Classifier is: {(lr_classifier.score(validX, validY))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_metric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8896/3133985597.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Also plot the metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_classifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Logistic Regression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_metric' is not defined"
     ]
    }
   ],
   "source": [
    "# Also plot the metric\n",
    "plot_metric(lr_classifier, validX, validY, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************\n",
    "### 2. Multinomial Naive Bayes\n",
    "Naive Bayes classifiers are a family of simple \"probabilistic classifiers\" based on applying Bayes' theorem with strong independence assumptions between the features. They are among the simplest Bayesian network models, but coupled with kernel density estimation, they can achieve higher accuracy levels.\n",
    "\n",
    "Let's now switch to the naive the bayes, the NAIVE BAYES!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Define and fit the classifier on the data\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Print the accuracy score of the classifier\n",
    "print(f\"Validation Accuracy of Naive Bayes Classifier is: {(nb_classifier.score(validX, validY))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Also plot the metric\n",
    "plot_metric(nb_classifier, validX, validY, \"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************\n",
    "### 3. Random Forest Classifier\n",
    "Random Forest is a popular machine learning algorithm that belongs to the supervised learning technique. It can be used for both Classification and Regression problems in ML. It is based on the concept of ensemble learning, which is a process of combining multiple classifiers to solve a complex problem and to improve the performance of the model.\n",
    "\n",
    "Let's now enter the forest with the Random Forest Classifier and see where it takes us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Define and fit the classifier on the data\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Print the accuracy score of the classifier\n",
    "print(f\"Validation Accuracy of Random Forest Classifier is: {(rf_classifier.score(validX, validY))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Also plot the metric\n",
    "plot_metric(nb_classifier, validX, validY, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************************************\n",
    "### 4. Decision Tree Classifier\n",
    "Decision Tree is a Supervised learning technique that can be used for both classification and Regression problems, but mostly it is preferred for solving Classification problems. It is a tree-structured classifier, where internal nodes represent the features of a dataset, branches represent the decision rules and each leaf node represents the outcome.\n",
    "\n",
    "Let's now take some decisions using the Decision Tree Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Define and fit the classifier on the data\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Print the accuracy score of the classifier\n",
    "print(f\"Validation Accuracy of Decision Tree Clf. is: {(dt_classifier.score(validX, validY))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Also plot the metric\n",
    "plot_metric(dt_classifier, validX, validY, \"Decision Tree Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**************************\n",
    "### 5. KNN Classifier\n",
    "K-Nearest Neighbour is one of the simplest Machine Learning algorithms based on Supervised Learning technique. K-NN algorithm assumes the similarity between the new case/data and available cases and put the new case into the category that is most similar to the available categories. K-NN algorithm stores all the available data and classifies a new data point based on the similarity. This means when new data appears then it can be easily classified into a well suite category by using K- NN algorithm.\n",
    "\n",
    "We now are going to use KNN Classifier for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Define and fit the classifier on the data\n",
    "kn_classifier = KNeighborsClassifier()\n",
    "kn_classifier.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Print the accuracy score of the classifier\n",
    "print(f\"Validation Accuracy of KNN Clf. is: {(kn_classifier.score(validX, validY))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Also plot the metric\n",
    "plot_metric(dt_classifier, validX, validY, \"Decision Tree Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************************\n",
    "### 6. XGBoost Classifier\n",
    "XGBoost is a decision-tree-based ensemble Machine Learning algorithm that uses a gradient boosting framework. In prediction problems involving unstructured data (images, text, etc.) A wide range of applications: Can be used to solve regression, classification, ranking, and user-defined prediction problems.\n",
    "\n",
    "Finally, let's use the XGBoost Classifier and then we'll compare all the different classifiers so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Define and fit the classifier on the data\n",
    "xg_classifier = XGBClassifier()\n",
    "xg_classifier.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Print the accuracy score of the classifier\n",
    "print(f\"Validation Accuracy of XGBoost Clf. is: {(xg_classifier.score(validX, validY))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# Also plot the metric\n",
    "plot_metric(xg_classifier, validX, validY, \"XGBoost Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************************\n",
    "### Comparing the models based on the accuracy scores\n",
    "We have deployed six machine learning algorithms and every algorithm is deployed successfully without any hesitation. We have checked the accuracy of the models based on the accuracy score of each of the models. Now let's take a look at the scores of each models.\n",
    "\n",
    "|Name of the Model|Accuracy Score|\n",
    "|:---:|:---:|\n",
    "|Logistic Regression|87.79%|\n",
    "|Decision Tree Classifier|79.72%|\n",
    "|Random Forest Classifier|82.96%|\n",
    "|Naive Bayes Algorithm|77.94%|\n",
    "|KNN Algorithm|56.51%|\n",
    "|XgBoost Classifier|87.86%|\n",
    "\n",
    "*************************************\n",
    "### Conclusion\n",
    "**Comparing all those scores scored by the machine learning algorithms, it is clear that Logistic Regression and XgBoost Classifier are having the upper hand in case of this dataset and after this, we can use Decision Tree Classifier, which is also having good score as compared to the other deployed algorithms**\n",
    "\n",
    "Best Fitted Models ranking - \n",
    "1. Logistic Regression\n",
    "2. XgBoosting Classifier\n",
    "3. Random Forest Classifier\n",
    "4. Decision Tree Calsssifier\n",
    "5. Multinomial Naive Bayes Classifier\n",
    "6. KNN Classifier\n",
    "\n",
    "Hooray!! The models are deployed successfully!\n",
    "\n",
    "\n",
    "### Hope this project will help you! Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
